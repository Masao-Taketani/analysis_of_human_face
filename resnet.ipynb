{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNetの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習前の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23697, 200, 200, 3), (23697,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = glob(\"data/UTKFace/*.jpg\")\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for img in imgs:\n",
    "    img_data = Image.open(img)\n",
    "    np_data = np.asarray(img_data)\n",
    "    filename = os.path.basename(img)\n",
    "    filename_split = [i for i in filename.split('_')]\n",
    "    X.append(np_data)\n",
    "    y.append(filename_split[1])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Red\">※</font>The difference between array and asarray is that `array` will make a copy of the input object while `asarray` will not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21327, 200, 200, 3) (21327,) (2370, 200, 200, 3) (2370,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの学習開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:77: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=666, validation_data=(array([[[..., verbose=1, epochs=200, max_queue_size=100, callbacks=[<keras.ca...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "666/666 [==============================] - 321s 481ms/step - loss: 0.3218 - acc: 0.8829 - val_loss: 0.3953 - val_acc: 0.8405\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39535, saving model to data/weights/val_loss0.395.hdf5\n",
      "Epoch 2/200\n",
      "666/666 [==============================] - 318s 477ms/step - loss: 0.3203 - acc: 0.8837 - val_loss: 0.6731 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.39535\n",
      "Epoch 3/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.3225 - acc: 0.8851 - val_loss: 0.3364 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39535 to 0.33642, saving model to data/weights/val_loss0.336.hdf5\n",
      "Epoch 4/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.3283 - acc: 0.8835 - val_loss: 0.4815 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33642\n",
      "Epoch 5/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.3239 - acc: 0.8862 - val_loss: 0.4065 - val_acc: 0.8485\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33642\n",
      "Epoch 6/200\n",
      "666/666 [==============================] - 317s 475ms/step - loss: 0.3333 - acc: 0.8807 - val_loss: 0.3318 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33642 to 0.33181, saving model to data/weights/val_loss0.332.hdf5\n",
      "Epoch 7/200\n",
      "666/666 [==============================] - 316s 474ms/step - loss: 0.3284 - acc: 0.8817 - val_loss: 0.3447 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33181\n",
      "Epoch 8/200\n",
      "666/666 [==============================] - 318s 477ms/step - loss: 0.3320 - acc: 0.8821 - val_loss: 0.4845 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33181\n",
      "Epoch 9/200\n",
      "666/666 [==============================] - 318s 477ms/step - loss: 0.3302 - acc: 0.8832 - val_loss: 0.4340 - val_acc: 0.8165\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.33181\n",
      "Epoch 10/200\n",
      "666/666 [==============================] - 317s 477ms/step - loss: 0.3244 - acc: 0.8868 - val_loss: 0.3257 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33181 to 0.32569, saving model to data/weights/val_loss0.326.hdf5\n",
      "Epoch 11/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.3289 - acc: 0.8859 - val_loss: 0.3240 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32569 to 0.32395, saving model to data/weights/val_loss0.324.hdf5\n",
      "Epoch 12/200\n",
      "666/666 [==============================] - 318s 477ms/step - loss: 0.3287 - acc: 0.8857 - val_loss: 0.4059 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32395\n",
      "Epoch 13/200\n",
      "666/666 [==============================] - 322s 484ms/step - loss: 0.3223 - acc: 0.8875 - val_loss: 0.4161 - val_acc: 0.8392\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.32395\n",
      "Epoch 14/200\n",
      "666/666 [==============================] - 318s 478ms/step - loss: 0.3262 - acc: 0.8858 - val_loss: 0.3730 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32395\n",
      "Epoch 15/200\n",
      "666/666 [==============================] - 317s 475ms/step - loss: 0.3222 - acc: 0.8861 - val_loss: 0.3628 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32395\n",
      "Epoch 16/200\n",
      "666/666 [==============================] - 330s 496ms/step - loss: 0.3270 - acc: 0.8857 - val_loss: 0.3378 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32395\n",
      "Epoch 17/200\n",
      "666/666 [==============================] - 318s 478ms/step - loss: 0.2896 - acc: 0.9034 - val_loss: 0.2965 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.32395 to 0.29650, saving model to data/weights/val_loss0.297.hdf5\n",
      "Epoch 18/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.2766 - acc: 0.9090 - val_loss: 0.3094 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29650\n",
      "Epoch 19/200\n",
      "666/666 [==============================] - 316s 474ms/step - loss: 0.2661 - acc: 0.9123 - val_loss: 0.2928 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.29650 to 0.29285, saving model to data/weights/val_loss0.293.hdf5\n",
      "Epoch 20/200\n",
      "666/666 [==============================] - 316s 475ms/step - loss: 0.2699 - acc: 0.9085 - val_loss: 0.2920 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.29285 to 0.29198, saving model to data/weights/val_loss0.292.hdf5\n",
      "Epoch 21/200\n",
      "666/666 [==============================] - 316s 475ms/step - loss: 0.2624 - acc: 0.9124 - val_loss: 0.2951 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29198\n",
      "Epoch 22/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.2578 - acc: 0.9150 - val_loss: 0.2967 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.29198\n",
      "Epoch 23/200\n",
      "666/666 [==============================] - 315s 473ms/step - loss: 0.2588 - acc: 0.9118 - val_loss: 0.2793 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.29198 to 0.27931, saving model to data/weights/val_loss0.279.hdf5\n",
      "Epoch 24/200\n",
      "666/666 [==============================] - 315s 474ms/step - loss: 0.2536 - acc: 0.9183 - val_loss: 0.3581 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.27931\n",
      "Epoch 25/200\n",
      "666/666 [==============================] - 315s 473ms/step - loss: 0.2535 - acc: 0.9165 - val_loss: 0.2996 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27931\n",
      "Epoch 26/200\n",
      "666/666 [==============================] - 315s 473ms/step - loss: 0.2472 - acc: 0.9179 - val_loss: 0.2967 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.27931\n",
      "Epoch 27/200\n",
      "666/666 [==============================] - 315s 472ms/step - loss: 0.2441 - acc: 0.9207 - val_loss: 0.4128 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.27931\n",
      "Epoch 28/200\n",
      "666/666 [==============================] - 316s 475ms/step - loss: 0.2483 - acc: 0.9166 - val_loss: 0.2940 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.27931\n",
      "Epoch 29/200\n",
      "666/666 [==============================] - 317s 476ms/step - loss: 0.2285 - acc: 0.9276 - val_loss: 0.2842 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.27931\n",
      "Epoch 30/200\n",
      "666/666 [==============================] - 315s 473ms/step - loss: 0.2208 - acc: 0.9301 - val_loss: 0.2874 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.27931\n",
      "Epoch 31/200\n",
      "666/666 [==============================] - 316s 475ms/step - loss: 0.2218 - acc: 0.9309 - val_loss: 0.2920 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.27931\n",
      "Epoch 32/200\n",
      "666/666 [==============================] - 315s 473ms/step - loss: 0.2165 - acc: 0.9329 - val_loss: 0.2958 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.27931\n",
      "Epoch 33/200\n",
      "666/666 [==============================] - 315s 473ms/step - loss: 0.2194 - acc: 0.9321 - val_loss: 0.2958 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.27931\n"
     ]
    }
   ],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('data/resnet152_sex_detection.csv')\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 200, 200\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128.\n",
    "X_test /= 128.\n",
    "\n",
    "model = ResnetBuilder.build_resnet_152((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.load_weights('data/weights/val_loss0.270.hdf5')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "weights_dir = 'data/weights/'\n",
    "if os.path.exists(weights_dir) == False:\n",
    "    os.mkdir(weights_dir)\n",
    "    \n",
    "checkpoint = ModelCheckpoint(weights_dir + \"val_loss{val_loss:.3f}.hdf5\",\n",
    "                              monitor = 'val_loss', verbose=1, save_best_only=True,\n",
    "                              save_weights_only = True, period=1)\n",
    "\n",
    "log = TensorBoard(log_dir = \"logs/\")\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[checkpoint, lr_reducer, early_stopper, csv_logger, log])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
